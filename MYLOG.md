# 依赖于 scrapy_redis 框架
# 因为需要修改到连接 redis 和处理新的 redis 数据存储的方式
# 并且又不能单纯的依赖于 scrapy_redis
# 所以直接拿 scrapy_redis 进行直接改造，主要是在 redis 的调度以及任务信息的存储上面进行一定程度的魔改。
# 考虑到多任务实现的框架的处理，所以就需要在一定情况下面进行更加细化的 id存储的调配处理
# 其中一些核心组件使用到了 scrapy 本身就有的组件，所以这部分也需要进行以插件形式的魔改
# 这样处理会更集成一点，并且在一定程度上依赖会小一些，不需要对 scrapy_redis 进行二次下载

# 1/ 考虑 spiderid   # 这个是考虑对 spiderid 执行状态的监控
# 2/ 考虑 taskid     # 这个是考虑对 taskid   任务主要的统计

# 后续的处理再看，先考虑实现功能

#20190505
# 目前的问题主要是在初始化上面，这里的初始化主要指的是 redis 数据结构设计
# 一方面要兼具 spiderid 和 taskid，另外还要考虑初始化的时机，确实有点麻烦的。

#20190510
# 继续补充注释的内容，后续可能要考虑怎么处理后续的结构上的问题。
# 处理多任务时候怎么让工具更加适配
# 下次的更新应该会再 scrapy_redis_mod.spiders 这里，主要是实现对任务的调度和处理上。
# 后续还可能需要突然死机后的重启恢复任务解决方式。很重要。

#20190511
# 尝试解决脚本传递的技术难点,力求无需特殊脚本处理的脚本传递方法.
# 尽量在不改变原脚本的基础上实现功能，都是为了方便而已
# 钩子还是稍微不够长，response 没有钩到，导致请求后回到 parse 函数内的 response 都没有我设置的传递参数
# 所以需要再测试几次在什么地方挂钩才能钩到这一个参数